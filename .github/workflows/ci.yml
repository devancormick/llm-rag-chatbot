name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  GITHUB_PAGES_BASE_URL: https://devancormick.github.io/llm-rag-chatbot

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run tests
        env:
          VECTOR_PROVIDER: chroma
          DATA_DIR: ${{ runner.temp }}/data
          LOG_LEVEL: WARNING
          BASE_URL: ""
          SIMILARITY_THRESHOLD: "0.5"
          TOP_K_CHUNKS: "8"
        run: |
          python -m unittest discover -s tests -v

  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install ruff
        run: pip install ruff

      - name: Lint
        run: ruff check api config.py ingestion leads rag vector_store run.py

  smoke:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Start app and smoke test
        env:
          VECTOR_PROVIDER: chroma
          DATA_DIR: ${{ runner.temp }}/data
          LOG_LEVEL: WARNING
          BASE_URL: ${{ env.GITHUB_PAGES_BASE_URL }}
          API_HOST: 127.0.0.1
          API_PORT: 8000
        run: |
          timeout 120 uvicorn api.main:app --host 127.0.0.1 --port 8000 &
          for i in $(seq 1 30); do
            if curl -fsS -o /dev/null -w "%{http_code}" http://127.0.0.1:8000/health 2>/dev/null | grep -q 200; then
              break
            fi
            sleep 4
          done
          curl -fsS -o /dev/null -w "%{http_code}" http://127.0.0.1:8000/health | grep -q 200
          curl -fsS http://127.0.0.1:8000/config | grep -q baseUrl
          curl -fsS http://127.0.0.1:8000/config | grep -q "$GITHUB_PAGES_BASE_URL"
          echo "Smoke test passed: /health and /config OK (BASE_URL=$GITHUB_PAGES_BASE_URL)"

  smoke-ollama:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh

      - name: Start Ollama and pull model
        run: |
          ollama serve &
          sleep 5
          ollama pull tinyllama

      - name: Start app and smoke test with Ollama
        env:
          VECTOR_PROVIDER: chroma
          DATA_DIR: ${{ runner.temp }}/data
          LOG_LEVEL: WARNING
          BASE_URL: ${{ env.GITHUB_PAGES_BASE_URL }}
          OLLAMA_BASE_URL: http://127.0.0.1:11434
          OLLAMA_MODEL: tinyllama
          API_HOST: 127.0.0.1
          API_PORT: 8000
        run: |
          timeout 120 uvicorn api.main:app --host 127.0.0.1 --port 8000 &
          for i in $(seq 1 45); do
            if curl -fsS -o /dev/null -w "%{http_code}" http://127.0.0.1:8000/health 2>/dev/null | grep -q 200; then
              break
            fi
            sleep 4
          done
          curl -fsS -o /dev/null -w "%{http_code}" http://127.0.0.1:8000/health | grep -q 200
          curl -fsS http://127.0.0.1:8000/config | grep -q baseUrl
          response=$(curl -fsS -X POST http://127.0.0.1:8000/chat -H "Content-Type: application/json" -d '{"question":"hi","top_k":2}')
          echo "$response" | grep -q "answer"
          echo "Smoke test with Ollama passed: /health, /config, /chat OK"
