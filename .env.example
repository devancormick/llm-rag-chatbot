# For Ollama Cloud use a cloud model: https://ollama.com/search?c=cloud (e.g. ministral-3:8b, gemini-3-flash-preview)
OLLAMA_MODEL=ministral-3:8b
OLLAMA_BASE_URL=http://localhost:11434
# Set OLLAMA_API_KEY to use Ollama Cloud instead of local. Get key at https://ollama.com/settings/keys
OLLAMA_API_KEY=

EMBEDDING_PROVIDER=sentence_transformers
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

OPENAI_API_KEY=
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_CHUNKS=5
SIMILARITY_THRESHOLD=0.7

VECTOR_PROVIDER=chroma

LOG_LEVEL=INFO
API_HOST=0.0.0.0
API_PORT=8000
BASE_URL=

# Data folder: uploads, Chroma DB, leads, and temp files go under DATA_DIR so project root stays clean.
# Leave empty to use ./data/ with: data/uploads, data/chroma_db, data/leads, data/tmp, data/faiss
DATA_DIR=
UPLOAD_DIR=
CHROMA_DIR=
LEADS_DIR=

PINECONE_API_KEY=
PINECONE_INDEX_NAME=llm-rag
PINECONE_NAMESPACE=default
PINECONE_DIMENSION=384
PINECONE_METRIC=cosine
PINECONE_CLOUD=aws
PINECONE_REGION=us-east-1

QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION_NAME=llm_rag_docs
QDRANT_DIMENSION=384
QDRANT_GRPC=false

DATABASE_URL=
PGVECTOR_CONNECTION_STRING=
PGVECTOR_TABLE_NAME=llm_rag_embeddings
PGVECTOR_DIMENSION=384
PGVECTOR_CREATE_EXTENSION=true

WEAVIATE_URL=http://localhost:8080
WEAVIATE_GRPC_PORT=50051
WEAVIATE_API_KEY=
WEAVIATE_COLLECTION_NAME=LlmRagChunk
WEAVIATE_DIMENSION=384

FAISS_INDEX_PATH=
FAISS_METADATA_PATH=
FAISS_DIMENSION=384
FAISS_NORMALIZE=true

MILVUS_URI=http://localhost:19530
MILVUS_USER=root
MILVUS_PASSWORD=Milvus
MILVUS_COLLECTION_NAME=llm_rag_docs
MILVUS_DIMENSION=384
MILVUS_INDEX_TYPE=IVF_FLAT
MILVUS_INDEX_PARAMS={"nlist": 1024}
MILVUS_SEARCH_PARAMS={"nprobe": 16}
